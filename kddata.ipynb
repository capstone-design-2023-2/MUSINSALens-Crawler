{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8b8d52ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to product_info.xlsx\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "# 웹페이지의 URL 설정\n",
    "url = 'https://www.musinsa.com/ranking/best?u_cat_cd='\n",
    "\n",
    "# 해당 URL로 요청을 보내서 HTML을 가져옴\n",
    "response = requests.get(url)\n",
    "\n",
    "# BeautifulSoup을 사용하여 HTML 파싱\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# 이미지를 저장할 디렉토리 생성\n",
    "image_dir = 'product_images'\n",
    "os.makedirs(image_dir, exist_ok=True)\n",
    "\n",
    "# 상품 정보를 담을 리스트 생성\n",
    "product_list = []\n",
    "\n",
    "# 원하는 요소를 찾아서 크롤링\n",
    "products = soup.find_all('li', class_='li_box')\n",
    "for product in products:\n",
    "    # 이미지 URL 가져오기\n",
    "    image_url = product.find('img')['data-original']\n",
    "    \n",
    "    # 제품 URL 가져오기\n",
    "    product_url_element = product.find('div',class_='list_img')\n",
    "    product_url = product_url_element.find('a')['href']\n",
    "\n",
    "    # 제품명 가져오기\n",
    "    product_name_element = product.find('p', class_='list_info')\n",
    "\n",
    "    # <strong> 태그 제외\n",
    "    strong_tag = product_name_element.find('strong', class_='txt_reserve')\n",
    "    if strong_tag:\n",
    "        strong_tag.extract()\n",
    "        \n",
    "    product_name = product_name_element.text.strip()\n",
    "\n",
    "    # 가격 가져오기\n",
    "    price_element = product.find('p', class_='price')\n",
    "    \n",
    "    # <del> 태그 내의 가격 가져오기\n",
    "    discount_price_element = price_element.find('del') if price_element else None\n",
    "    discount_price = discount_price_element.text.strip() if discount_price_element else ''\n",
    "    \n",
    "    # <del> 태그 제거\n",
    "    del_tag = price_element.find('del')\n",
    "    if del_tag:\n",
    "        del_tag.extract()\n",
    "    \n",
    "    price = price_element.text.strip()\n",
    "    \n",
    "    # 브랜드명 가져오기\n",
    "    brand_element = product.find('p', class_='item_title')\n",
    "    \n",
    "    #brand = brand_element.find('a')\n",
    "    # <span> 태그 제거\n",
    "    #span_tag = brand_element.find('span')\n",
    "    #if span_tag:\n",
    "        #span_tag.extract()\n",
    "\n",
    "    brand = brand_element.text.strip()\n",
    "\n",
    "    # 상품 이름에서 사용할 수 없는 문자 제거\n",
    "    product_name = re.sub(r'[\\/:*?\"<>|]', '', product_name)\n",
    "\n",
    "    # 상품 정보를 딕셔너리로 저장\n",
    "    product_info = {\n",
    "        '이미지 URL': image_url,\n",
    "        '제품 URL' : product_url,\n",
    "        '브랜드명' : brand,\n",
    "        '제품명': product_name,\n",
    "        '가격': price,\n",
    "        '할인되기 전 가격': discount_price\n",
    "    }\n",
    "\n",
    "    product_list.append(product_info)\n",
    "    \n",
    "# 이미지 다운로드 및 정보 저장\n",
    "for idx, product_info in enumerate(product_list):\n",
    "    \n",
    "    product_url = product_info['제품 URL']\n",
    "    \n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'}\n",
    "    product_response = requests.get(product_url, headers=headers)\n",
    "    product_soup = BeautifulSoup(product_response.text, 'html.parser')\n",
    "    \n",
    "    \n",
    "    item_categories_element = product_soup.find('p', class_=\"item_categories\")\n",
    "    categories = item_categories_element.find_all('a')\n",
    "    item_categories = [category.text.strip() for category in categories]\n",
    "    \n",
    "    \n",
    "    product_image = product_soup.find('img', class_='plus_cursor')\n",
    "    product_image_url = urljoin(product_url, product_image['src'])\n",
    "            \n",
    "    image_data = requests.get(product_image_url).content\n",
    "    image_filename = os.path.join(image_dir, f'{product_info[\"제품명\"]}.jpg')\n",
    "    with open(image_filename, 'wb') as image_file:\n",
    "        image_file.write(image_data)\n",
    "    \n",
    "    product_info['상품 카테고리'] = item_categories\n",
    "    \n",
    "    #image_url = product_info['이미지 URL']\n",
    "    #product_name = product_info['제품명']\n",
    "    #price = product_info['가격']\n",
    "    \n",
    "    # 이미지 다운로드\n",
    "    #image_data = requests.get(image_url).content\n",
    "    #image_filename = os.path.join(image_dir, f'{product_name}.jpg')\n",
    "    #with open(image_filename, 'wb') as image_file:\n",
    "        #image_file.write(image_data)\n",
    "\n",
    "# 데이터프레임 생성\n",
    "df = pd.DataFrame(product_list)\n",
    "\n",
    "# 엑셀 파일로 저장\n",
    "excel_filename = 'product_info.xlsx'\n",
    "df.to_excel(excel_filename, index=False)\n",
    "\n",
    "# 결과 출력\n",
    "print(f'Data saved to {excel_filename}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6611378",
   "metadata": {},
   "source": [
    "## short_sleeve_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77cf2672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to short_sleeve_top_product_info.xlsx\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "# 웹페이지의 URL 설정\n",
    "url = 'https://www.musinsa.com/ranking/best?period=now&age=ALL&mainCategory=001&subCategory=001001&leafCategory=&price=&golf=false&kids=false&newProduct=false&exclusive=false&discount=false&soldOut=false&page=1&viewType=small&priceMin=&priceMax='\n",
    "\n",
    "# 해당 URL로 요청을 보내서 HTML을 가져옴\n",
    "response = requests.get(url)\n",
    "\n",
    "# BeautifulSoup을 사용하여 HTML 파싱\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# 이미지를 저장할 디렉토리 생성\n",
    "image_dir = 'short_sleeve_top_product_images'\n",
    "os.makedirs(image_dir, exist_ok=True)\n",
    "\n",
    "# 상품 정보를 담을 리스트 생성\n",
    "product_list = []\n",
    "\n",
    "# 원하는 요소를 찾아서 크롤링\n",
    "products = soup.find_all('li', class_='li_box')\n",
    "for product in products:\n",
    "    # 이미지 URL 가져오기\n",
    "    image_url = product.find('img')['data-original']\n",
    "    \n",
    "    # 제품 URL 가져오기\n",
    "    product_url_element = product.find('div',class_='list_img')\n",
    "    product_url = product_url_element.find('a')['href']\n",
    "\n",
    "    # 제품명 가져오기\n",
    "    product_name_element = product.find('p', class_='list_info')\n",
    "\n",
    "    # <strong> 태그 제외\n",
    "    strong_tag = product_name_element.find('strong', class_='txt_reserve')\n",
    "    if strong_tag:\n",
    "        strong_tag.extract()\n",
    "        \n",
    "    product_name = product_name_element.text.strip()\n",
    "\n",
    "    # 가격 가져오기\n",
    "    price_element = product.find('p', class_='price')\n",
    "    \n",
    "    # <del> 태그 내의 가격 가져오기\n",
    "    discount_price_element = price_element.find('del') if price_element else None\n",
    "    discount_price = discount_price_element.text.strip() if discount_price_element else ''\n",
    "    \n",
    "    # <del> 태그 제거\n",
    "    del_tag = price_element.find('del')\n",
    "    if del_tag:\n",
    "        del_tag.extract()\n",
    "    \n",
    "    price = price_element.text.strip()\n",
    "    \n",
    "    # 브랜드명 가져오기\n",
    "    brand_element = product.find('p', class_='item_title')\n",
    "    \n",
    "    #brand = brand_element.find('a')\n",
    "    # <span> 태그 제거\n",
    "    #span_tag = brand_element.find('span')\n",
    "    #if span_tag:\n",
    "        #span_tag.extract()\n",
    "\n",
    "    brand = brand_element.text.strip()\n",
    "\n",
    "    # 상품 이름에서 사용할 수 없는 문자 제거\n",
    "    product_name = re.sub(r'[\\/:*?\"<>|]', '', product_name)\n",
    "\n",
    "    # 상품 정보를 딕셔너리로 저장\n",
    "    product_info = {\n",
    "        '이미지 URL': image_url,\n",
    "        '제품 URL' : product_url,\n",
    "        '브랜드명' : brand,\n",
    "        '제품명': product_name,\n",
    "        '가격': price,\n",
    "        '할인되기 전 가격': discount_price\n",
    "    }\n",
    "\n",
    "    product_list.append(product_info)\n",
    "    \n",
    "# 이미지 다운로드 및 정보 저장\n",
    "for idx, product_info in enumerate(product_list):\n",
    "    \n",
    "    product_url = product_info['제품 URL']\n",
    "    \n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'}\n",
    "    product_response = requests.get(product_url, headers=headers)\n",
    "    product_soup = BeautifulSoup(product_response.text, 'html.parser')\n",
    "    \n",
    "    #카테고리\n",
    "    item_categorie_big = '상의'\n",
    "    item_categorie_small = '반소매 티셔츠'\n",
    "    \n",
    "    #좋아요 갯수\n",
    "    #like_count_element = product_soup.find('span', class_='prd_like_cnt')\n",
    "    #like_count = like_count_element.find('span', {'name': 'count'}).text.strip() if like_count_element else ''\n",
    "    \n",
    "    #리뷰 갯수\n",
    "    #review_count_element = product_soup.find('span', class_='prd-score__review-count')\n",
    "    #review_count = review_count_element.find('span', {'name': 'count'}).text.strip() if like_count_element else ''\n",
    "    \n",
    "    \n",
    "    product_image = product_soup.find('img', class_='plus_cursor')\n",
    "    product_image_url = urljoin(product_url, product_image['src'])\n",
    "            \n",
    "    image_data = requests.get(product_image_url).content\n",
    "    image_filename = os.path.join(image_dir, f'{product_info[\"제품명\"]}.jpg')\n",
    "    with open(image_filename, 'wb') as image_file:\n",
    "        image_file.write(image_data)\n",
    "    \n",
    "    product_info['카테고리(대)'] = item_categorie_big\n",
    "    product_info['카테고리(중)'] = item_categorie_small\n",
    "    #product_info['좋아요 갯수'] = like_count\n",
    "    #product_info['리뷰 갯수'] = review_count\n",
    "\n",
    "# 데이터프레임 생성\n",
    "df = pd.DataFrame(product_list)\n",
    "\n",
    "# 엑셀 파일로 저장\n",
    "excel_filename = 'short_sleeve_top_product_info.xlsx'\n",
    "df.to_excel(excel_filename, index=False)\n",
    "\n",
    "# 결과 출력\n",
    "print(f'Data saved to {excel_filename}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8ef573",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
